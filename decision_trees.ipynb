{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decision_trees.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeshavGulati/Flexbox-ch-04/blob/master/decision_trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree & Random Forest Tutorial"
      ],
      "metadata": {
        "id": "Ewpt79vPGB_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD6ZuvGB9sFn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we want to look at the distribution of the dataset. This is an important first step that many often skip, so always remember to do it! It's extremely important to know the breakdown of your data."
      ],
      "metadata": {
        "id": "yLF7t2knFx19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "total_labels = np.concatenate([train_labels, test_labels])\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
        "classes, freqs = np.unique(total_labels, return_counts=True)\n",
        "ax.bar(classes, freqs)\n",
        "ax.set_xticks(classes);"
      ],
      "metadata": {
        "id": "ltM-F0Si-0S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the first question one may have is how a decision tree helps classify images. Essentially, the idea is that we can replicate the ideas of image filters by having the decision tree check individual pixels for their values. If a group of pixels exhibit a certain desired feature, then that should be encoded as a pathway on the decision tree."
      ],
      "metadata": {
        "id": "XJWm6BOqCLmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, however, we need to transform all our images into one dimensional vectors. There's a variety of ways to do this, but the simplest is to simply just flatten the images. It's boring, but it works."
      ],
      "metadata": {
        "id": "NOjUHJ2KDJMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that MNIST images are 28 x 28, so we just need to flatten our arrays to shape (n, 784)\n",
        "\n",
        "train_vecs, test_vecs = train_images.reshape(train_images.shape[0], 784), test_images.reshape(test_images.shape[0], 784)\n",
        "train_vecs.shape, test_vecs.shape"
      ],
      "metadata": {
        "id": "21MzgF-fCHiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Play with the hyperparameters!\n",
        "dtree = DecisionTreeClassifier(max_depth=5)\n",
        "rf = RandomForestClassifier(n_estimators=10, max_depth=5)\n",
        "\n",
        "dtree.fit(train_vecs, train_labels)\n",
        "rf.fit(train_vecs, train_labels)\n",
        "\n",
        "print(\"Classifiers trained\")"
      ],
      "metadata": {
        "id": "zsneVDh8DlXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome, let's test these guys out now!"
      ],
      "metadata": {
        "id": "McxcDpfDEcx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtree_preds = dtree.predict(test_vecs)\n",
        "rf_preds = rf.predict(test_vecs)"
      ],
      "metadata": {
        "id": "tTMLUHq8EGUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "def plot_confmat(true_labels, pred_labels):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix from given data\n",
        "    \"\"\"\n",
        "    fig2, ax = plt.subplots(1, 1, num=2, figsize=(10, 10))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize the confusion matrix\n",
        "    for pair in np.argwhere(np.isnan(cm_norm)):\n",
        "        cm_norm[pair[0]][pair[1]] = 0\n",
        "\n",
        "    annot = np.zeros_like(cm, dtype=object)\n",
        "    for i in range(annot.shape[0]):  # Creates an annotation array for the heatmap\n",
        "        for j in range(annot.shape[1]):\n",
        "            annot[i][j] = f'{cm[i][j]}\\n{round(cm_norm[i][j] * 100, ndigits=3)}%'\n",
        "\n",
        "    ax = sns.heatmap(cm_norm, annot=annot, fmt='', cbar=True, cmap=plt.cm.magma, vmin=0, ax=ax) # plot the confusion matrix\n",
        "    ax.set_title(f'Accuracy = {round(accuracy_score(true_labels, pred_labels), 2) * 100}%')\n",
        "    ax.set(xlabel='Predicted Label', ylabel='Actual Label')\n",
        "    \n",
        "    fig2.tight_layout()"
      ],
      "metadata": {
        "id": "xnUM0dSCEg-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Decision Tree Confusion Matrix')\n",
        "plot_confmat(test_labels, dtree_preds)"
      ],
      "metadata": {
        "id": "oSrhebOJEoF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Random Forest Confusion Matrix')\n",
        "plot_confmat(test_labels, rf_preds)"
      ],
      "metadata": {
        "id": "5P7RFei8FISa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cTciFjebFODn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}